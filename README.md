# ğŸ§  AI SysOps Observability â€” DetecciÃ³n de anomalÃ­as para recursos del sistema

> Sistema **ligero y local** de **observabilidad inteligente** para ingenieros **SysOps**. Monitorea CPU y memoria, **aprende un baseline** y alerta ante **comportamientos anÃ³malos** usando *Isolation Forest*. Ideal para labs, demos y portafolios, **sin dependencias en la nube**.

<p align="left">
  <img alt="License" src="https://img.shields.io/badge/license-MIT-black">
  <img alt="Python" src="https://img.shields.io/badge/python-3.8+-blue">
  <img alt="ML" src="https://img.shields.io/badge/ML-Isolation%20Forest-orange">
  <img alt="Offline" src="https://img.shields.io/badge/offline-100%25-success">
</p>

---

## âœ¨ Funcionalidades

* ğŸ“Š **Monitoreo** de uso de **CPU** y **memoria (RAM)** en tiempo real
* ğŸ¤– **DetecciÃ³n de anomalÃ­as** con **Isolation Forest** (entrenamiento en datos simulados)
* ğŸ§  **Entrenamiento rÃ¡pido** de modelo: baseline local vs. ruido/anomalÃ­as simuladas
* ğŸš¨ **Alertas** cuando el sistema se desvÃ­a del comportamiento esperado
* ğŸ§ª **Modo demo** libre de riesgos: sin AWS, sin root, sin tocar servicios del sistema

---

## ğŸ§­ Flujo de alto nivel

```mermaid
flowchart LR
  A["psutil metrics<br/>CPU%, MEM%"] --> B["Ventana de features<br/>(window_size)"]
  B --> C["Modelo IA<br/>Isolation Forest"]
  C -->|score &lt; threshold| D[Alert Manager]
  D --> E1[stdout]
  D --> E2[archivo logs]
  D --> E3[webhook opc.]
```

---

## ğŸ“‚ Estructura

```
.
â”œâ”€ train_model.py        # Entrena y guarda el modelo (joblib)
â”œâ”€ monitor.py            # Lee mÃ©tricas y evalÃºa el modelo en tiempo real
â”œâ”€ requirements.txt      # Dependencias
â”œâ”€ config.example.yml    # (opcional) Config por YAML
â”œâ”€ .env.example          # (opcional) Config por variables de entorno
â””â”€ README.md
```

> Puedes usar **.env** o **config.yml** (elige uno). Si no existen, se usan **valores por defecto seguros**.

---

## âš™ï¸ Requisitos

* **Python 3.8+** (recomendado 3.10+)
* **Dependencias**:

  * `scikit-learn`
  * `psutil`
  * `joblib`
  * `numpy`

```bash
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
```

**Ejemplo `requirements.txt`:**

```
scikit-learn>=1.3
psutil>=5.9
joblib>=1.3
numpy>=1.24
PyYAML>=6.0  # si usas config YAML (opcional)
python-dotenv>=1.0  # si usas .env (opcional)
```

---

## ğŸš€ Uso rÃ¡pido

```bash
# 1) Instalar dependencias
pip install -r requirements.txt

# 2) Entrenar (genera artifacts/model.joblib)
python train_model.py

# 3) Monitorear en vivo (usa el modelo entrenado)
python monitor.py
```

**Salida esperada (ejemplo):**

```
[train] dataset: 5m baseline + 2% ruido
[train] model: IsolationForest(contamination=0.02)
[train] saved: artifacts/model.joblib

[monitor] tick=12 cpu=23.1% mem=41.8% score=0.27 status=OK
[monitor] tick=13 cpu=92.4% mem=87.9% score=-0.14 status=ANOMALY âš ï¸
```

---

## ğŸ”§ ConfiguraciÃ³n

### Variables de entorno (`.env`)

| Variable          | DescripciÃ³n                              | Default                  |
| ----------------- | ---------------------------------------- | ------------------------ |
| `MODEL_PATH`      | Ruta del modelo entrenado                | `artifacts/model.joblib` |
| `SAMPLE_INTERVAL` | Intervalo de muestreo (seg.)             | `1.0`                    |
| `WINDOW_SIZE`     | TamaÃ±o de ventana para features          | `30`                     |
| `ALERT_THRESHOLD` | Umbral de score p/ alerta (<0 = anÃ³malo) | `0.0`                    |
| `LOG_PATH`        | Archivo de logs                          | `logs/monitor.log`       |
| `WEBHOOK_URL`     | URL webhook para alertas (opcional)      | *vacÃ­o*                  |

### Config YAML (`config.yml`)

```yaml
model_path: artifacts/model.joblib
sample_interval: 1.0
window_size: 30
alert_threshold: 0.0
log_path: logs/monitor.log
webhook_url: ""
```

> **Prioridad sugerida:** flags CLI â†’ variables de entorno â†’ config.yml â†’ defaults.

---

## ğŸ§ª CÃ³mo probar anomalÃ­as

**OpciÃ³n 1 (rÃ¡pida):** abre temporalmente una carga de CPU en otra terminal:

```bash
python - <<'PY'
import time
x = 0
while True:
  x = (x + 1) % 10**6
  if x==0: time.sleep(0.001)
PY
```

**OpciÃ³n 2 (Linux):** instala `stress`/`stress-ng` y simula picos (opcional).
**OpciÃ³n 3:** modifica `monitor.py` para activar un modo `--simulate` (si lo implementas).

> DetÃ©n los procesos con `Ctrl+C` cuando termines. No uses en servidores compartidos.

---

## ğŸ§° CLI sugerida (opcional)

Si decides aÃ±adir flags:

```
python train_model.py --minutes 5 --contamination 0.02 --save artifacts/model.joblib
python monitor.py --interval 1.0 --window 30 --threshold 0.0 --log logs/monitor.log
```

---

## ğŸ§¯ Troubleshooting

* **No encuentra modelo** â†’ ejecuta `python train_model.py` o revisa `MODEL_PATH`.
* **Permisos en logs** â†’ crea `logs/` y otorga permisos: `mkdir -p logs && chmod 755 logs`.
* **picos falsos de CPU** â†’ sube `WINDOW_SIZE` o ajusta `ALERT_THRESHOLD`.
* **alto uso de CPU del monitor** â†’ incrementa `SAMPLE_INTERVAL`.

---

## ğŸ§ª CI/CD (sugerencia)

* **Lint/format:** `ruff`/`flake8` + `black`
* **Tests:** `pytest` con muestras artificiales
* **Seguridad:** `pip-audit` o `safety`
* Workflow base: `.github/workflows/ci.yml` (instalar deps â†’ lint â†’ tests)

---

## ğŸ—ºï¸ Roadmap

* [ ] Exporter **Prometheus** (mÃ©tricas `anomaly_score`, `is_anomaly`)
* [ ] Dashboard **Grafana** de ejemplo
* [ ] Persistencia de features/ventanas para anÃ¡lisis postâ€‘mortem
* [ ] DetecciÃ³n de **data/model drift** y reâ€‘entrenamiento programado
* [ ] IntegraciÃ³n de **webhooks** (Slack/Discord) para alertas
* [ ] Empaquetado **Docker** y `docker-compose.yml` de demo

---

## ğŸ”’ Seguridad y privacidad

* No recolecta datos personales ni envÃ­a telemetrÃ­a externa.
* Todo corre **local/offline**.
* Revisa el cÃ³digo si lo usas en entornos sensibles.

---

## ğŸ‘¤ Autor

**Â© 2025 Emanuel** â€” Licencia **MIT**
**LinkedIn:** [https://www.linkedin.com/in/emanuel-gonzalez-michea/](https://www.linkedin.com/in/emanuel-gonzalez-michea/)



